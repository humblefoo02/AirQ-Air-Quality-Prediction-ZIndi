{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Analiza poziomu PM2.5 w afrykańskich miastach</center>\n",
    "### Zespół:\n",
    "<ol>\n",
    "    <li style='font-size: 20px'>Hubert Kłosowski 242424</li>\n",
    "    <li style='font-size: 20px'>Krzysztof Kolanek 242425</li>\n",
    "    <li style='font-size: 20px'>Kamil Małecki 242464</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a096af4d2cacc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Potrzebne importy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a57b6008c92140"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.impute import KNNImputer\n",
    "from sympy import divisors\n",
    "from scipy.stats import zscore\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, RFE, mutual_info_regression, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import optuna"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f44b8667be4021ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wczytanie danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c7a6517c9f58e8"
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('data\\\\Train.csv')\n",
    "test = pd.read_csv('data\\\\Test.csv')\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8195eb62bb5596b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcef3f3066b6dcaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rozbicie daty na składowe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af49ecab4176ea4c"
  },
  {
   "cell_type": "code",
   "source": [
    "def change_date(dataframe):\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
    "    dataframe['day'] = dataframe['date'].dt.dayofweek.astype(np.int64)\n",
    "    dataframe['month'] = dataframe['month'].astype(np.int64)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "data, test = change_date(data), change_date(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96de3f55dc052fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający jakość powietrza w krajach afrykańskich"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdbb93a09da5579d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.lineplot(data=data, x='date', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c080d74ffd38ea41",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 w zarejestrowanych godzinach"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c18ec25179e58a3d"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='hour', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w poszczególnych godzinach z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cc187b6375c9eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od dnia tygodnia"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b3fd78e799e096"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='day', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36c6ec9520527975",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykres przedstawiający wartość pm2_5 z zależności od miesiąca"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c018df974513e0e3"
  },
  {
   "cell_type": "code",
   "source": [
    "sns.barplot(data=data, x='month', y='pm2_5', hue='country')\n",
    "plt.title('Jakość powietrza w każdym dniu tygodnia z podziałem na kraje')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b6234a9ec5ca95",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Korelacje poszczególnych grup kolumn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "785f97dcd77bdb1c"
  },
  {
   "cell_type": "code",
   "source": [
    "def correlation():\n",
    "    for i, column in enumerate(starts_with):\n",
    "        selected_columns = [col for col in data.columns if col.startswith(column) or col == 'pm2_5']\n",
    "        if len(selected_columns) > 1:\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            sns.heatmap(data[selected_columns].corr(), annot=True, fmt='.2f', cmap='viridis', ax=ax)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "def drop_high_correlated_columns(dataframe):\n",
    "    matrix = dataframe.corr(numeric_only=True)\n",
    "    upper = matrix.where(np.triu(np.ones(matrix.shape), k=1).astype(np.bool_))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] >= 0.9)]\n",
    "    return dataframe.drop(to_drop, axis=1)\n",
    "\n",
    "\n",
    "final_ids = test['id']\n",
    "starts_with = data.columns.str.split('_', expand=True).levels[0].to_frame()\n",
    "starts_with.drop(['month', 'day', 'hour', 'pm2'], inplace=True)\n",
    "starts_with = starts_with[0].tolist()\n",
    "data, test = drop_high_correlated_columns(data), drop_high_correlated_columns(test)\n",
    "data.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "test.drop(columns=['id', 'city', 'country', 'site_id', 'date'], inplace=True)\n",
    "\n",
    "correlation()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67d0ec8072327669",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Czyszczenie danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3216061cba4b3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Uzupełnienie wartości brakujących"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba2f9b8e1bcb96ad"
  },
  {
   "cell_type": "code",
   "source": [
    "def fill_based_on(dataframe, date_unit='day'):\n",
    "    date_range = dataframe[date_unit].unique()\n",
    "    for date in date_range:\n",
    "        for i, column in enumerate(starts_with):\n",
    "            similar_columns = [el for el in dataframe.columns if el.startswith(column)]\n",
    "            df = dataframe.loc[dataframe[date_unit] == date, similar_columns]\n",
    "            if not df.empty:\n",
    "                dataframe.loc[dataframe[date_unit] == date, similar_columns] = imputers[i].fit_transform(df)\n",
    "    return dataframe\n",
    "\n",
    "def prepare_dataframe(dataframe):  # usuwamy kolumny o dużej liczbie wartości NaN\n",
    "    to_drop = []\n",
    "    for i, el in enumerate(dataframe.columns):\n",
    "        if dataframe[el].isna().sum() / len(dataframe) >= 0.9:\n",
    "            to_drop.append(el)\n",
    "    dataframe.drop(to_drop, axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "imputers = [KNNImputer(n_neighbors=15, weights='distance') for _ in range(len(starts_with))]\n",
    "data, test = prepare_dataframe(data), prepare_dataframe(test)\n",
    "data, test = fill_based_on(data), fill_based_on(test)\n",
    "vertical_columns = [col for col in data.columns if 'number_density' in col]\n",
    "ver = dict(zip(vertical_columns, [(abs(data[column].quantile(0.1)) * -1.5 / data[column].std(), abs(data[column].quantile(0.9)) * 1.5 / data[column].std()) for column in vertical_columns]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "133fbc1ffe6ae43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wykresy pudełkowe wskazujące wartości odstające"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9af06f017aaea4c3"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_boxplots():\n",
    "    for i, column_group in enumerate(starts_with):\n",
    "        similar_columns = [col for col in data.columns if col.startswith(column_group)]\n",
    "        if len(similar_columns) > 1:\n",
    "            divs = divisors(len(similar_columns))\n",
    "            if len(divs) % 2 == 0:\n",
    "                rows, cols = divs[(len(divs) // 2) - 1], divs[len(divs) // 2]\n",
    "            else:\n",
    "                rows, cols = divs[len(divs) // 2], divs[len(divs) // 2]\n",
    "            fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(40, 30), squeeze=False)\n",
    "            fig.suptitle(column_group, fontsize=25)\n",
    "            for j, column in enumerate(similar_columns):\n",
    "                x_cord, y_cord = divmod(j, cols)\n",
    "                data[column].plot(kind='box', ax=ax[x_cord, y_cord], fontsize=15)\n",
    "                if column in ver.keys():\n",
    "                    ax[x_cord, y_cord].axhline(y=ver.get(column)[0] * data[column].std(), color='green', label='down-limit')\n",
    "                    ax[x_cord, y_cord].axhline(y=ver.get(column)[1] * data[column].std(), color='red', label='up-limit')\n",
    "                ax[x_cord, y_cord].legend(loc='best')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "plot_boxplots()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7901bc4c9d7d1412",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Usunięcie wartości odstających"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a767724811d79e3c"
  },
  {
   "cell_type": "code",
   "source": [
    "def del_outliers(dataframe, ignore_down_range=True):\n",
    "    for column, zscore_range in ver.items():\n",
    "        vec, indexes = zscore(dataframe[column]), []\n",
    "        for j in range(len(vec)):\n",
    "            if ignore_down_range:\n",
    "                if vec[j] >= zscore_range[1]:\n",
    "                    indexes.append(j)\n",
    "            else:\n",
    "                if zscore_range[0] <= vec[j] >= zscore_range[1]:\n",
    "                    indexes.append(j)\n",
    "        dataframe.drop(index=indexes, inplace=True)\n",
    "        dataframe.reset_index(drop=True, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "data = del_outliers(data)\n",
    "\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e31da0f18fee574",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "data.head()",
   "metadata": {
    "collapsed": false
   },
   "id": "3463da86e8af6bd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Selekcja cech</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9161db0ea237c"
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_feature_importance(sc, num_of_features):\n",
    "    if isinstance(sc, RFECV) or isinstance(sc, RFE):\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.ranking_))\n",
    "    else:\n",
    "        scores = dict(zip(sc.feature_names_in_, sc.scores_))\n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:num_of_features]\n",
    "    scores_df = pd.DataFrame(scores, columns=['Feature', 'Score'])\n",
    "    \n",
    "    scores_df.plot(kind='bar', x='Feature', y='Score', figsize=(10, 6), rot=90, title='Oceny wybranych cech')\n",
    "    plt.xlabel('Cecha')\n",
    "    plt.ylabel('Ocena')\n",
    "\n",
    "\n",
    "X, y = data.drop(['pm2_5'], axis=1), data['pm2_5']\n",
    "# selector = RFE(\n",
    "#     estimator=RandomForestRegressor(\n",
    "#         n_estimators=700, \n",
    "#         max_depth=7, \n",
    "#         random_state=4, \n",
    "#         n_jobs=-1, \n",
    "#         oob_score=True,\n",
    "#         warm_start=True\n",
    "#     ),\n",
    "#     n_features_to_select=k,\n",
    "# )\n",
    "k = 25\n",
    "selector = RFECV(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=400, \n",
    "        max_depth=10, \n",
    "        random_state=4, \n",
    "        n_jobs=-1, \n",
    "        oob_score=True,\n",
    "        warm_start=True,\n",
    "    ),\n",
    "    min_features_to_select=k, \n",
    "    cv=10, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "selector.fit(X, y)\n",
    "X, test = selector.transform(X), selector.transform(test)\n",
    "\n",
    "plot_feature_importance(selector, k)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c002ded9461774c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Transformacja danych</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b9be23efdbd904"
  },
  {
   "cell_type": "markdown",
   "source": "### 1. Wybór sposobu preprocessingu danych",
   "metadata": {
    "collapsed": false
   },
   "id": "22bf5b75d8429019"
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X, y)\n",
    "test = scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "376c12ae9287f590",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Podział na zbiór testowy i treningowy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c70912092f074e4"
  },
  {
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)",
   "metadata": {
    "collapsed": false
   },
   "id": "683541f15475f393",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <center>Część obliczeniowa</center>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea367ef409a37a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Otrzymanie najlepszych parametrów",
   "id": "9831b50f952a24eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def give_the_best(clf, param_grid):\n",
    "    gs = GridSearchCV(clf, param_grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=5)\n",
    "    gs.fit(X_train, y_train)\n",
    "    return gs.best_estimator_\n",
    "\n",
    "def save_to_csv(y_pred, save_as):\n",
    "    final_df = pd.concat([final_ids, pd.DataFrame.from_dict({'pm2_5': y_pred})], axis=1)\n",
    "    final_df.to_csv(f'result\\\\{save_as}', index=False)"
   ],
   "id": "e9d2d344d5d30f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>Regresja przy użyciu MLP</center>",
   "id": "cc72c66908bb5e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# params = {\n",
    "#     'hidden_layer_sizes': [(99, 141, 75)],\n",
    "#     'activation': ['relu'],\n",
    "#     'solver': ['adam'],\n",
    "#     'max_iter': [1000],\n",
    "#     'alpha': np.linspace(0.0001, 0.001, 10),\n",
    "#     'batch_size': [64, 128, 256],\n",
    "#     'learning_rate_init': np.linspace(0.001, 0.01, 10),\n",
    "#     'warm_start': [True],\n",
    "#     'early_stopping': [True],\n",
    "#     'validation_fraction': [0.1]\n",
    "# }\n",
    "# \n",
    "# mlp = give_the_best(MLPRegressor())\n",
    "# save_to_csv(mlp.predict(test), 'mlp.csv')\n",
    "# print('Parametry MLP: ', mlp.get_params())\n",
    "# print('RMSE: ', root_mean_squared_error(y_test, mlp.predict(X_test)))"
   ],
   "id": "ed5f063582c3c0e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <center>PyTorch</center>",
   "id": "d8bd09cb2fae5106"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Wybór karty graficznej do nauki modelu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaf607cc44710975"
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    'cuda'\n",
    "    if torch.cuda.is_available()\n",
    "    else 'mps'\n",
    "    if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, device=device, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, device=device, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), device=device, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), device=device, dtype=torch.float)\n",
    "test_tensor = torch.tensor(test, device=device, dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ea7f2091127d19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Optuna",
   "id": "6784e54b9ac8486f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    layers = []\n",
    "    \n",
    "    in_features = X_train_tensor.shape[1]\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f'layer{i}', 25, 200)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(f'dropout{i}', 0, 0.4)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def objective(trial):\n",
    "    model = define_model(trial).to(device=device)\n",
    "    lr = trial.suggest_float('lr', 1e-3, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-4, log=True)\n",
    "    betas = (trial.suggest_float('beta1', 0.8, 0.9, log=True), trial.suggest_float('beta2', 0.997, 0.999, log=True))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay, betas=betas, fused=True)\n",
    "    \n",
    "    batch_size = trial.suggest_int('batch_size', 16, 416, step=25)\n",
    "    criterion = rmse_loss\n",
    "    epochs = trial.suggest_int('epochs', 100, 300, step=50)\n",
    "    \n",
    "    final_train_tensor = torch.concat((X_train_tensor, y_train_tensor.unsqueeze(dim=1)), dim=1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        dataset = DataLoader(final_train_tensor, batch_size=batch_size, shuffle=True)\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataset):\n",
    "            inputs, targets = batch[:, :-1], batch[:, -1]\n",
    "            batch_pred = model(inputs)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(targets, batch_pred.squeeze())\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        trial.report(epoch_loss / len(dataset), epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor).squeeze()\n",
    "        \n",
    "    return root_mean_squared_error(y_test, y_pred.numpy(force=True))\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    study_name='AirQuality',\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ],
   "id": "a612d991969930d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Najlepsze parametry sieci neuronowej",
   "metadata": {
    "collapsed": false
   },
   "id": "aff1a14b2bea3818"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study.best_params",
   "id": "9cfb05cde113e0af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający każdy <i>trial</i> w procesie nauki",
   "id": "7dd9e64e1b394237"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_optimization_history(study)",
   "id": "8f7608eef0ccc810",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja przekroju parametrów",
   "id": "f9d8406114339ed0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_slice(study, params=['lr', 'n_layers', 'weight_decay', 'beta1', 'beta2', 'epochs', 'batch_size'])",
   "id": "8142b6308c8970fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Zależność parametrów w postaci wykresu konturowego",
   "id": "6e8600ed39b005cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_contour(study, params=['lr', 'n_layers', 'beta1', 'beta2', 'epochs', 'batch_size'])",
   "id": "2f4ffefa4dda681b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres przedstawiający wielowymiarowe zależności parametrów",
   "id": "ac781e5abf8585da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_parallel_coordinate(study, params=['lr', 'n_layers', 'beta1', 'beta2', 'epochs', 'batch_size'])",
   "id": "bf78850a6ed46b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Historia optymalizacji parametrów na osi czasu",
   "id": "85a51722879427ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optuna.visualization.plot_timeline(study)",
   "id": "df6f0912abade9f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <center>Do wysłania</center>",
   "id": "79bf1209e752a444"
  },
  {
   "cell_type": "code",
   "source": [
    "best_model = define_model(study.best_trial)\n",
    "best_model.to(device=device)\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    save_to_csv(best_model(test_tensor).squeeze().numpy(force=True), 'nn.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ce5044d06598de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dodatkowe informacje\n",
    "<ol>\n",
    "    <li>The 15km SO2 band is ingested only when solar_zenith_angle < 70.</li>\n",
    "    <li>Because of noise on the data, negative vertical column values are often observed in particular over clean regions or for low SO2 emissions. It is recommended not to filter these values except for outliers, i.e. for vertical columns lower than -0.001 mol/m^2.</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2128d77bca7e777"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
